## Обзор

Хотя нейронные сети получили широкое признание в области искусственного интеллекта, они не являются единственной ключевой моделью в этой сфере. Искусственный интеллект включает множество классических моделей, каждая из которых имеет свои уникальные особенности. В этой главе мы обсудим несколько моделей, которые либо тесно связаны с нейронными сетями, либо хорошо сочетаются с ними. Эти модели включают **деревья решений** и их производные модели, **скрытые марковские модели** и **обучение без учителя**.

1. **Деревья решений** — это интуитивно понятные и легко интерпретируемые модели, которые являются выдающимся примером коннекционизма в моделировании. На практике деревья решений часто используются в сочетании с другими моделями. Они могут извлекать ключевые признаки и повышать интерпретируемость модели благодаря своей чёткой структуре. Кроме того, деревья решений могут интегрироваться сами с собой, образуя более мощные производные модели, такие как случайные леса и градиентные бустинговые деревья.
2. **Скрытые марковские модели** (Hidden Markov Models, HMM) в своё время пользовались большой популярностью и применялись в таких областях, как распознавание речи и финансовые рынки. Особенно в финансовой сфере, знаменитый фонд Medallion Fund, названный "самым прибыльным квантовым фондом в истории", использовал скрытые марковские модели. Эту модель можно рассматривать как частный случай рекуррентных нейронных сетей, что и является причиной её включения в эту главу.
3. Модели, обсуждаемые ранее, будь то простая линейная регрессия или сложные большие языковые модели, относятся к области обучения с учителем. То есть они требуют наличия меток в данных. Однако в реальных приложениях часто встречаются ситуации, когда метки отсутствуют. В таких случаях используются модели обучения без учителя. В этой главе мы рассмотрим три типа моделей обучения без учителя: кластеризация, понижение размерности и сингулярное разложение.

Содержание этой главы может показаться несколько самостоятельным, но оно расширяет кругозор и помогает глубже понять происхождение и суть некоторых технологий в нейронных сетях.

## Описание кода

| Код | Описание |
| --- | --- |
| [dt_example.ipynb](dt_example.ipynb) | Модель дерева решений |
| [dt_logit.ipynb](dt_logit.ipynb) | Связь между деревом решений и логистической регрессией, использование дерева решений для извлечения признаков |
| [gbts.ipynb](gbts.ipynb) | Градиентные бустинговые деревья |
| [viterbipy.py](viterbipy.py) | Реализация алгоритма Витерби |
| [stock_analysis.ipynb](stock_analysis.ipynb) | Анализ данных китайского фондового рынка с использованием скрытой марковской модели |
| [kmeans.ipynb](kmeans.ipynb) | Алгоритм кластеризации — KMeans |
| [kmeans_choose_k.ipynb](kmeans_choose_k.ipynb) | Как выбрать количество кластеров |
| [pca.ipynb](pca.ipynb) | Алгоритм понижения размерности — метод главных компонент |
