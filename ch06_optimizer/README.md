## Обзор

Как обсуждалось в предыдущих главах, при создании модели сначала рассматривают реальные сценарии применения, предварительно анализируют характеристики данных, чтобы получить вдохновение и интуицию. Затем, через математическую абстракцию и преобразование, выбирают подходящую архитектуру модели для решения задачи. В заключение, используя открытые библиотеки алгоритмов на Python, реализуют конечную модель, параметры которой уже были оценены.

С точки зрения проектирования программного обеспечения, открытые алгоритмические библиотеки на Python превосходны в области абстракции (Abstraction). Они эффективно скрывают детали реализации построения и обучения моделей, позволяя нам сосредоточиться только на высокоуровневых концепциях и операциях, таких как предоставляемые функции интерфейса (API). С помощью этих интерфейсов часто можно построить и обучить модель всего за несколько десятков строк кода. В этом процессе нет необходимости углубляться в сложные математические вычисления, лежащие в основе модели, и алгоритмы оценки параметров модели больше не представляют собой преграду. В идеальных условиях вся сложность нижнего уровня абстрагируется, и работа дата-сайентиста становится более легкой и удобной (разумеется, с другой стороны, это может привести к снижению порога входа в профессию, что повлияет на количество вакансий и уровень заработной платы). Однако, к сожалению (или к счастью), поскольку модели включают сложные математические абстракции и вычисления, даже при идеальном проектировании и абстракции не удается полностью скрыть их сложность, и некоторые детали все же могут "просочиться", влияя на понимание и использование системы пользователем, что называется **утечкой абстракции** (Leaky Abstraction).

Например, при обучении модели логистической регрессии некоторые наборы данных могут вызвать ошибки в открытой библиотеке алгоритмов, не позволяя оценить параметры модели. В случае относительно классических или простых моделей утечка абстракции встречается реже. Однако для более сложных моделей, таких как глубокое обучение и большие языковые модели в области нейронных сетей, возможно множество проблем с утечкой абстракции. Без понимания деталей реализации нижнего уровня в этих областях будет трудно продвигаться: с теоретической точки зрения невозможно понять суть модели и эффективно оптимизировать её, чтобы достичь ожидаемых результатов; с практической точки зрения будет сложно устранить проблемы в программе, долгие времена обучения, а также будет трудно гибко использовать библиотеки алгоритмов и корректировать архитектуру модели в соответствии с потребностями.

Поэтому в этой главе будет углубленное исследование ключевых деталей открытых библиотек алгоритмов, обсуждение того, как на основе математических формул модели вычислить соответствующие оценочные значения параметров. С более академической точки зрения, это исследование алгоритмов решения задач оптимизации. Задачи оптимизации можно решать различными методами, и разные алгоритмы подходят для разных моделей и имеют свои преимущества в решении различных типов задач. В этой главе, учитывая ограничение объема, будет сделан акцент на наиболее важных и широко применяемых алгоритмах: методе градиентного спуска, методе стохастического градиентного спуска и их различных вариантах.

## Описание кода

| Код | Описание |
| --- | --- |
| [pytorch_tutorial.ipynb](pytorch_tutorial.ipynb) | Операции с тензорами и основные операции |
| [gradient_descent.ipynb](gradient_descent.ipynb) | Реализация метода градиентного спуска с использованием PyTorch |
| [stochastic_gradient_descent.ipynb](stochastic_gradient_descent.ipynb) | Реализация метода стохастического градиентного спуска с использованием PyTorch |
